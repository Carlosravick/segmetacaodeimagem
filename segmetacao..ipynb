{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opendatasets\n",
    "!pip install pandas\n",
    "!pip install imagehash\n",
    "!pip install glob\n",
    "!pip install kagglehub\n",
    "!pip install tensorflow\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import opendatasets as od\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import kagglehub\n",
    "import glob\n",
    "import imagehash\n",
    "%matplotlib inline\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from imgaug import augmenters as iaa\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/aryashah2k/breast-ultrasound-images-dataset/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_corrupted = 0\n",
    "corrupted = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list = list()\n",
    "for folder in os.listdir(root_dir):\n",
    "  child_dir = os.path.join(root_dir, folder)\n",
    "\n",
    "  for image in os.listdir(child_dir):\n",
    "    img_dir = os.path.join(child_dir, image)\n",
    "    _, image_format = image.split('.')\n",
    "    img = cv2.imread(img_dir)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if img is not None:\n",
    "      # Converter a imagem OpenCV para uma imagem do Pillow\n",
    "      img_pil = Image.fromarray(img_rgb)\n",
    "\n",
    "      # Gerar o hash da imagem (usando perceptual hash como exemplo)\n",
    "      img_hash = imagehash.phash(img_pil)\n",
    "      width, height, channels = img.shape\n",
    "      img_corrupted = False\n",
    "    else:\n",
    "      count_corrupted += 1\n",
    "      corrupted.append(img_dir)\n",
    "      img_corrupted = True\n",
    "      img_hash, image_format, width, height, channels = None, None, None, None, None\n",
    "\n",
    "    dataframe_list.append([img_dir, img_corrupted, img_hash, image_format, width, height, channels, folder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['image_path', 'corrupted', 'image_hash', 'image_format', 'width', 'height', 'channels', 'label'], data = dataframe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().loc[['mean', 'std', 'min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "image_format_counts = df['image_format'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=image_format_counts.index, y=image_format_counts.values, palette=\"Greens\", width=0.40)\n",
    "\n",
    "plt.title('Número de Imagens por formato', fontsize=16)\n",
    "plt.xlabel('Formato da Imagem', fontsize=12)\n",
    "plt.ylabel('Número de Imagens', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benigno\n",
    "diretorio_benign = \"/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign\"\n",
    "\n",
    "image_count = 0\n",
    "for subdir, dirs, files in os.walk(diretorio_benign):\n",
    "    for file in files:\n",
    "        if file.endswith(('.png')):\n",
    "            image_count += 1\n",
    "\n",
    "print(f\"Total de imagens no diretório de benigno: {image_count}\")\n",
    "\n",
    "## Normal\n",
    "diretorio_normal = \"/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/normal\"\n",
    "\n",
    "image_count = 0\n",
    "\n",
    "for subdir, dirs, files in os.walk(diretorio_normal):\n",
    "    for file in files:\n",
    "        if file.endswith(('.png')):\n",
    "            image_count += 1\n",
    "\n",
    "print(f\"Total de imagens no diretório normal: {image_count}\")\n",
    "\n",
    "#Maligno\n",
    "diretorio_malignant = \"/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/malignant\"\n",
    "\n",
    "image_count = 0\n",
    "\n",
    "for subdir, dirs, files in os.walk(diretorio_malignant):\n",
    "    for file in files:\n",
    "        if file.endswith(('.png')):\n",
    "            image_count += 1\n",
    "\n",
    "print(f\"Total de imagens no diretório maligno: {image_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de imagens corrompidas\n",
    "count_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images = pd.DataFrame(dataframe_list, columns=['Path', 'Corrupted', 'Hash', 'Format', 'Width', 'Height', 'Channels', 'Folder'])\n",
    "print(f\"Imagens corrompidas: {count_corrupted}\")\n",
    "print(df_images.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica valores ausentes\n",
    "valores_ausentes = df.isnull().sum()\n",
    "\n",
    "print(\"Valores ausentes em cada coluna:\")\n",
    "print(valores_ausentes[valores_ausentes > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo limites esperados para largura e altura\n",
    "largura_minima = 150\n",
    "largura_maxima = 800\n",
    "altura_minima = 150\n",
    "altura_maxima = 1200\n",
    "\n",
    "# Verificando dimensões inconsistentes\n",
    "dimensoes_inconsistentes = df[(df['width'] < largura_minima) |\n",
    "                               (df['width'] > largura_maxima) |\n",
    "                               (df['height'] < altura_minima) |\n",
    "                               (df['height'] > altura_maxima)]\n",
    "\n",
    "# Exibindo resultados\n",
    "if not dimensoes_inconsistentes.empty:\n",
    "    print(\"Dimensões inconsistentes encontradas:\")\n",
    "    print(dimensoes_inconsistentes[['image_path', 'width', 'height']])\n",
    "else:\n",
    "    print(\"Todas as dimensões das imagens estão dentro dos limites esperados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicatas = df[df.duplicated(subset='image_path', keep=False)]\n",
    "if not duplicatas.empty:\n",
    "    print(\"Imagens duplicadas encontradas:\")\n",
    "    print(duplicatas[['image_path']])\n",
    "else:\n",
    "    print(\"Não foram encontradas imagens duplicadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular o hash da imagem\n",
    "def calculate_image_hash(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    return imagehash.average_hash(image)\n",
    "\n",
    "# Dicionário para armazenar hashes e seus caminhos de imagem\n",
    "hash_dict = defaultdict(list)\n",
    "\n",
    "# Percorrer diretório e subdiretórios\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            img_hash = calculate_image_hash(file_path)\n",
    "            hash_dict[img_hash].append(file_path)\n",
    "\n",
    "# Encontrar e listar imagens duplicadas\n",
    "duplicates = {k: v for k, v in hash_dict.items() if len(v) > 1}\n",
    "\n",
    "# Exibir resultados\n",
    "if duplicates:\n",
    "    count = 0\n",
    "    print(\"Imagens duplicadas encontradas:\")\n",
    "    for img_hash, paths in duplicates.items():\n",
    "        for path in paths:\n",
    "            count = count + 1\n",
    "    print(f\" - {count}\")\n",
    "else:\n",
    "    print(\"Nenhuma imagem duplicada encontrada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "# Diretório raiz\n",
    "root_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n",
    "\n",
    "# Função para calcular o hash da imagem\n",
    "def calculate_image_hash(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    return imagehash.average_hash(image)\n",
    "\n",
    "# Verificar e remover duplicatas\n",
    "hash_dict = defaultdict(list)\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            img_hash = calculate_image_hash(file_path)\n",
    "            hash_dict[img_hash].append(file_path)\n",
    "\n",
    "# Encontrar e remover duplicatas (mantendo apenas uma cópia)\n",
    "for img_hash, paths in hash_dict.items():\n",
    "    if len(paths) > 1:\n",
    "        for path in paths[1:]:\n",
    "            os.remove(path)\n",
    "\n",
    "# Contar e salvar imagens restantes em cada pasta\n",
    "counts = {'benign': 0, 'malignant': 0, 'normal': 0}\n",
    "for category in counts.keys():\n",
    "    category_dir = os.path.join(root_dir, category)\n",
    "    for _, _, files in os.walk(category_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                counts[category] += 1\n",
    "                file_path = os.path.join(category_dir, file)\n",
    "                # Reabrir e salvar a imagem para confirmar que está salva\n",
    "                with Image.open(file_path) as img:\n",
    "                    img.save(file_path)\n",
    "\n",
    "# Exibir contagem de imagens restantes\n",
    "for category, count in counts.items():\n",
    "    print(f'Pasta {category}: {count} imagens restantes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Diretório raiz\n",
    "root_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n",
    "\n",
    "# Função para contar imagens em cada categoria\n",
    "def count_images(directory):\n",
    "    counts = {'benign': 0, 'malignant': 0, 'normal': 0}\n",
    "\n",
    "    for category in counts.keys():\n",
    "        category_dir = os.path.join(directory, category)\n",
    "        if os.path.isdir(category_dir):\n",
    "            for file in os.listdir(category_dir):\n",
    "                if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                    counts[category] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "# Chamar a função e exibir os resultados\n",
    "image_counts = count_images(root_dir)\n",
    "\n",
    "for category, count in image_counts.items():\n",
    "    print(f'Pasta {category}: {count} imagens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(counts):\n",
    "    categories = list(counts.keys())\n",
    "    values = list(counts.values())\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(categories, values, color=['blue', 'red', 'green'])\n",
    "    plt.title(\"Distribuição de Imagens por Classe Após Remoção de Duplicatas\")\n",
    "    plt.xlabel(\"Classes\")\n",
    "    plt.ylabel(\"Número de Imagens\")\n",
    "    plt.show()\n",
    "\n",
    "# Chamar a função para gerar o gráfico\n",
    "plot_distribution(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Tamanhos desejados\n",
    "new_width = 224\n",
    "new_height = 224\n",
    "\n",
    "# Função para redimensionar, salvar e mostrar imagens\n",
    "def process_and_save_images(directory, num_images=4):\n",
    "    images_displayed = 0\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for subdir, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                if images_displayed >= num_images:\n",
    "                    break\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                image = cv2.imread(file_path)\n",
    "\n",
    "                # Redimensionar a imagem\n",
    "                resized_image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "                # Salvar a imagem redimensionada\n",
    "                cv2.imwrite(file_path, resized_image)\n",
    "\n",
    "                # Mostrar as imagens original e redimensionada\n",
    "                plt.subplot(2, 4, images_displayed * 2 + 1)\n",
    "                plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                plt.title('Imagem Original')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(2, 4, images_displayed * 2 + 2)\n",
    "                plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "                plt.title('Imagem Redimensionada')\n",
    "                plt.axis('off')\n",
    "\n",
    "                images_displayed += 1\n",
    "\n",
    "        if images_displayed >= num_images:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Diretório raiz\n",
    "root_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanhos desejados\n",
    "new_width = 224\n",
    "new_height = 224\n",
    "\n",
    "# Função para redimensionar e salvar imagens\n",
    "def resize_and_save_images(directory):\n",
    "    for subdir, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "\n",
    "                # Abrir a imagem\n",
    "                with Image.open(file_path) as img:\n",
    "                    # Redimensionar a imagem\n",
    "                    resized_image = img.resize((new_width, new_height))\n",
    "                    # Salvar a imagem redimensionada\n",
    "                    resized_image.save(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para mostrar imagens redimensionadas\n",
    "def display_images(directory, num_images=4):\n",
    "    images_displayed = 0\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for subdir, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                if images_displayed >= num_images:\n",
    "                    break\n",
    "                file_path = os.path.join(subdir, file)\n",
    "\n",
    "                # Abrir a imagem redimensionada\n",
    "                image = cv2.imread(file_path)\n",
    "\n",
    "                # Mostrar a imagem redimensionada\n",
    "                plt.subplot(1, num_images, images_displayed + 1)\n",
    "                plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                plt.title('Imagem Redimensionada')\n",
    "                plt.axis('off')\n",
    "\n",
    "                images_displayed += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter as dimensões das imagens\n",
    "def get_image_dimensions(directory):\n",
    "    for folder in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for image_name in os.listdir(folder_path):\n",
    "                image_path = os.path.join(folder_path, image_name)\n",
    "                try:\n",
    "                    with Image.open(image_path) as img:\n",
    "                        width, height = img.size\n",
    "                        print(f'Imagem: {image_name} | Dimensões: {width}x{height}')\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao abrir {image_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_save_images(root_dir)\n",
    "display_images(root_dir)\n",
    "get_image_dimensions(root_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar e mostrar as imagens no diretório raiz\n",
    "for category in counts.keys():\n",
    "    print(f'\\nMostrando imagens da pasta: {category}')\n",
    "    category_dir = os.path.join(root_dir, category)\n",
    "    process_and_display_images(category_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Diretório raiz\n",
    "root_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n",
    "\n",
    "# Função para normalizar, salvar e mostrar imagens\n",
    "def normalize_save_and_display_images(directory, num_images=4):\n",
    "    images_displayed = 0\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for subdir, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "\n",
    "                # Abrir a imagem\n",
    "                image = cv2.imread(file_path)\n",
    "                if image is None:\n",
    "                    print(f\"Erro ao abrir a imagem: {file_path}\")\n",
    "                    continue\n",
    "\n",
    "                # Normalizar a imagem (valores entre 0 e 1)\n",
    "                normalized_image = image / 255.0\n",
    "\n",
    "                # Converter de volta para uint8 para salvar\n",
    "                normalized_image_uint8 = (normalized_image * 255).astype(np.uint8)\n",
    "\n",
    "                # Salvar a imagem normalizada\n",
    "                cv2.imwrite(file_path, normalized_image_uint8)\n",
    "\n",
    "                # Mostrar as imagens original e normalizada\n",
    "                if images_displayed < num_images:\n",
    "                    plt.subplot(2, 4, images_displayed * 2 + 1)\n",
    "                    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                    plt.title('Imagem Original')\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.subplot(2, 4, images_displayed * 2 + 2)\n",
    "                    plt.imshow(cv2.cvtColor(normalized_image_uint8, cv2.COLOR_BGR2RGB))\n",
    "                    plt.title('Imagem Normalizada')\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    images_displayed += 1\n",
    "\n",
    "        if images_displayed >= num_images:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Processar, normalizar, salvar e mostrar as imagens no diretório raiz\n",
    "for category in ['benign', 'malignant', 'normal']:\n",
    "    print(f'\\nMostrando imagens da pasta: {category}')\n",
    "    category_dir = os.path.join(root_dir, category)\n",
    "    normalize_save_and_display_images(category_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para corrigir o contraste usando CLAHE\n",
    "def adjust_contrast_clahe(directory):\n",
    "    for subdir, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Aplicar CLAHE para realce adaptativo de contraste\n",
    "                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "                clahe_image = clahe.apply(image)\n",
    "\n",
    "                # Salvar a imagem com CLAHE aplicado\n",
    "                cv2.imwrite(file_path, clahe_image)\n",
    "\n",
    "# Aplicar CLAHE nas imagens do diretório raiz\n",
    "for category in counts.keys():\n",
    "    category_dir = os.path.join(root_dir, category)\n",
    "    adjust_contrast_clahe(category_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para reduzir ruído\n",
    "def denoise_images(directory):\n",
    "    for subdir, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                image = cv2.imread(file_path)\n",
    "\n",
    "                # Redução de ruído usando filtro bilateral\n",
    "                denoised_image = cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "                # Salvar a imagem com ruído reduzido\n",
    "                cv2.imwrite(file_path, denoised_image)\n",
    "\n",
    "# Reduzir o ruído das imagens no diretório raiz\n",
    "for category in counts.keys():\n",
    "    category_dir = os.path.join(root_dir, category)\n",
    "    denoise_images(category_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para mostrar algumas imagens\n",
    "def display_images(directory, num_images=4):\n",
    "    images_displayed = 0\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for subdir, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                if images_displayed >= num_images:\n",
    "                    break\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                image = cv2.imread(file_path)\n",
    "\n",
    "                # Mostrar a imagem\n",
    "                plt.subplot(1, num_images, images_displayed + 1)\n",
    "                plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                plt.title(f'Imagem {images_displayed + 1}')\n",
    "                plt.axis('off')\n",
    "\n",
    "                images_displayed += 1\n",
    "\n",
    "        if images_displayed >= num_images:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Processar e mostrar as imagens no diretório raiz\n",
    "for category in counts.keys():\n",
    "    print(f'\\nMostrando imagens da pasta: {category}')\n",
    "    category_dir = os.path.join(root_dir, category)\n",
    "    display_images(category_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Função para fazer data augmentation e salvar novas imagens\n",
    "def augment_images(input_dir, output_dir, target_count):\n",
    "    images = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    current_count = len(images)\n",
    "\n",
    "    if current_count >= target_count:\n",
    "        print(f\"A pasta {input_dir} já está balanceada.\")\n",
    "        return current_count\n",
    "\n",
    "    num_to_create = target_count - current_count\n",
    "    aug = iaa.Sequential([\n",
    "        iaa.Affine(rotate=(-25, 25)),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Multiply((0.8, 1.2)),\n",
    "    ])\n",
    "\n",
    "    print(f\"Criando {num_to_create} novas imagens para {input_dir}...\")\n",
    "\n",
    "    for i in range(num_to_create):\n",
    "        img_path = np.random.choice(images)\n",
    "        image = Image.open(img_path)\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        augmented_image = aug(image=image_array)\n",
    "        augmented_pil = Image.fromarray(augmented_image)\n",
    "\n",
    "        save_path = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(img_path))[0]}_aug_{i}.png\")\n",
    "        augmented_pil.save(save_path)\n",
    "\n",
    "    return len(os.listdir(input_dir))\n",
    "\n",
    "# Função para contar imagens\n",
    "def count_images(directory, categories):\n",
    "    counts = {}\n",
    "    for category in categories:\n",
    "        category_dir = os.path.join(directory, category)\n",
    "        counts[category] = len([f for f in os.listdir(category_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    return counts\n",
    "\n",
    "# Caminho do diretório raiz\n",
    "root_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n",
    "categories = ['benign', 'malignant', 'normal']\n",
    "\n",
    "# Contagem antes do balanceamento\n",
    "counts_before = count_images(root_dir, categories)\n",
    "print(\"Contagem antes do balanceamento:\", counts_before)\n",
    "\n",
    "# Balancear as classes\n",
    "target_count = counts_before['benign']  # Número de imagens de 'benign'\n",
    "counts_after = {\n",
    "    'benign': counts_before['benign'],\n",
    "    'malignant': augment_images(os.path.join(root_dir, 'malignant'), os.path.join(root_dir, 'malignant'), target_count),\n",
    "    'normal': augment_images(os.path.join(root_dir, 'normal'), os.path.join(root_dir, 'normal'), target_count)\n",
    "}\n",
    "\n",
    "# Contagem após o balanceamento\n",
    "counts_after = count_images(root_dir, categories)\n",
    "print(\"Contagem após o balanceamento:\", counts_after)\n",
    "\n",
    "# Plotar gráfico de distribuição\n",
    "def plot_distribution(counts_before, counts_after):\n",
    "    categories = counts_before.keys()\n",
    "    values_before = list(counts_before.values())\n",
    "    values_after = list(counts_after.values())\n",
    "\n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, values_before, width, label='Antes do Balanceamento', color='skyblue')\n",
    "    plt.bar(x + width/2, values_after, width, label='Depois do Balanceamento', color='orange')\n",
    "\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Número de Imagens')\n",
    "    plt.title('Distribuição de Imagens Antes e Depois do Balanceamento')\n",
    "    plt.xticks(x, categories)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plot_distribution(counts_before, counts_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Defina o diretório onde as imagens estão armazenadas\n",
    "root_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n",
    "\n",
    "# Função para obter as dimensões das imagens\n",
    "def get_image_dimensions(root_dir):\n",
    "    for folder in os.listdir(root_dir):\n",
    "        folder_path = os.path.join(root_dir, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for image_name in os.listdir(folder_path):\n",
    "                image_path = os.path.join(folder_path, image_name)\n",
    "                try:\n",
    "                    # Abra a imagem e obtenha suas dimensões\n",
    "                    with Image.open(image_path) as img:\n",
    "                        width, height = img.size\n",
    "                        print(f'Imagem: {image_name} | Dimensões: {width}x{height}')\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao abrir {image_name}: {e}\")\n",
    "\n",
    "# Chame a função\n",
    "get_image_dimensions(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Diretório raiz\n",
    "root_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n",
    "\n",
    "# Função para contar imagens em cada categoria\n",
    "def count_images(directory):\n",
    "    counts = {'benign': 0, 'malignant': 0, 'normal': 0}\n",
    "\n",
    "    for category in counts.keys():\n",
    "        category_dir = os.path.join(directory, category)\n",
    "        if os.path.isdir(category_dir):\n",
    "            for file in os.listdir(category_dir):\n",
    "                if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                    counts[category] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "# Chamar a função e exibir os resultados\n",
    "image_counts = count_images(root_dir)\n",
    "\n",
    "for category, count in image_counts.items():\n",
    "    print(f'Pasta {category}: {count} imagens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório raiz\n",
    "root_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n",
    "\n",
    "# Função para carregar imagens e máscaras\n",
    "def load_images_and_masks(directory):\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for label in ['benign', 'malignant', 'normal']:\n",
    "        class_dir = os.path.join(directory, label)\n",
    "\n",
    "        if not os.path.exists(class_dir):\n",
    "            print(f\"Warning: Directory not found: {class_dir}\")\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(class_dir):\n",
    "            if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                image_path = os.path.join(class_dir, file)\n",
    "\n",
    "                mask_file_name = file.split('.')[0] + '_mask.png'\n",
    "                mask_path = os.path.join(class_dir, mask_file_name)\n",
    "\n",
    "                if not os.path.exists(mask_path):\n",
    "                    print(f\"Warning: Mask file not found for image: {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.resize(image, (224, 224)).astype('float32') / 255.0  # Normalizar e converter para float32\n",
    "\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if mask is not None:\n",
    "                    mask = cv2.resize(mask, (224, 224)).astype('float32') / 255.0  # Normalizar e converter para float32\n",
    "                else:\n",
    "                    print(f\"Warning: Failed to load mask: {mask_path}\")\n",
    "                    continue\n",
    "\n",
    "                images.append(image)\n",
    "                masks.append(mask)\n",
    "\n",
    "    if len(images) == 0 or len(masks) == 0:\n",
    "        print(\"Erro: Nenhuma imagem ou máscara foi carregada.\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Carregar imagens e máscaras\n",
    "X, y = load_images_and_masks(root_dir)\n",
    "\n",
    "# Verificar se as imagens e máscaras foram carregadas corretamente\n",
    "if X.size == 0 or y.size == 0:\n",
    "    print(\"Erro ao carregar as imagens ou máscaras.\")\n",
    "else:\n",
    "    print(f\"Total de imagens carregadas: {X.shape[0]}\")\n",
    "    print(f\"Total de máscaras carregadas: {y.shape[0]}\")\n",
    "\n",
    "    # Dividir os dados em treino e validação\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"Dados de treino: {X_train.shape}, {y_train.shape}\")\n",
    "    print(f\"Dados de validação: {X_val.shape}, {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet50_unet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "\n",
    "    # Encoder: Extração de características\n",
    "    c1 = base_model.get_layer(\"conv1_relu\").output\n",
    "    c2 = base_model.get_layer(\"conv2_block3_out\").output\n",
    "    c3 = base_model.get_layer(\"conv3_block4_out\").output\n",
    "    c4 = base_model.get_layer(\"conv4_block6_out\").output\n",
    "    c5 = base_model.get_layer(\"conv5_block3_out\").output\n",
    "\n",
    "    # Decoder: Construção da U-Net\n",
    "    u1 = UpSampling2D(size=(2, 2))(c5)\n",
    "    u1 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(u1)\n",
    "    u1 = concatenate([u1, c4])\n",
    "\n",
    "    u2 = UpSampling2D(size=(2, 2))(u1)\n",
    "    u2 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(u2)\n",
    "    u2 = concatenate([u2, c3])\n",
    "\n",
    "    u3 = UpSampling2D(size=(2, 2))(u2)\n",
    "    u3 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(u3)\n",
    "    u3 = concatenate([u3, c2])\n",
    "\n",
    "    u4 = UpSampling2D(size=(2, 2))(u3)\n",
    "    u4 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(u4)\n",
    "    u4 = concatenate([u4, c1])\n",
    "\n",
    "    u5 = UpSampling2D(size=(2, 2))(u4)\n",
    "    u5 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(u5)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation=\"sigmoid\")(u5)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = build_resnet50_unet((224, 224, 3))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "plt.plot(history.history['loss'], label='Perda de Treinamento')\n",
    "plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
    "plt.title('Curva de Perda')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Perda: {loss}')\n",
    "print(f'Acurácia: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perda combinada\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=[1,2,3])\n",
    "    return 1 - (2. * intersection + 1.) / (sum_ + 1.)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    bce_loss = K.binary_crossentropy(y_true, y_pred)\n",
    "    dice_loss_val = dice_loss(y_true, y_pred)\n",
    "    return bce_loss + dice_loss_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aumento de dados com Keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def unet(input_size=(256, 256, 1)):\n",
    "    inputs = layers.Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Decoder\n",
    "    up3 = layers.UpSampling2D(size=(2, 2))(conv2)\n",
    "    concat3 = layers.concatenate([up3, conv1], axis=3)\n",
    "    conv3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(concat3)\n",
    "    conv3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv3)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "model = unet()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)  # Normalização para [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Normalizar as imagens\n",
    "datagen = ImageDataGenerator(rescale=1./255)  # Normaliza para [0, 1]\n",
    "\n",
    "# Dados para treinamento\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT',  # Caminho do diretório\n",
    "    target_size=(256, 256),  # Tamanho das imagens de entrada\n",
    "    batch_size=32,  # Tamanho do lote\n",
    "    class_mode='categorical',  # Rótulos em formato one-hot codificado (múltiplas classes)\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Caminhos dos diretórios\n",
    "val_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/val'\n",
    "test_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/test'\n",
    "\n",
    "# Verificar se o diretório de validação existe\n",
    "if not os.path.exists(val_dir):\n",
    "    print(f\"O diretório {val_dir} não foi encontrado!\")\n",
    "else:\n",
    "    # Criar as pastas de teste se não existirem\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Classes: benign, malignant, normal\n",
    "    classes = ['benign', 'malignant', 'normal']\n",
    "\n",
    "    # Dividir 50% dos arquivos de validação para o diretório de teste\n",
    "    for class_name in classes:\n",
    "        val_class_dir = os.path.join(val_dir, class_name)\n",
    "        test_class_dir = os.path.join(test_dir, class_name)\n",
    "\n",
    "        # Verificar se a pasta da classe existe\n",
    "        if not os.path.exists(val_class_dir):\n",
    "            print(f\"Erro: O diretório {val_class_dir} não existe.\")\n",
    "            continue\n",
    "\n",
    "        # Criar o diretório da classe dentro de test, se não existir\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "        # Obter todos os arquivos de imagem da classe\n",
    "        images = [img for img in os.listdir(val_class_dir) if img.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "        # Verificar se há imagens\n",
    "        if len(images) == 0:\n",
    "            print(f\"A classe {class_name} não contém imagens.\")\n",
    "            continue\n",
    "\n",
    "        # Selecionar 50% das imagens para mover para o diretório de teste\n",
    "        num_test_images = len(images) // 2\n",
    "        test_images = random.sample(images, num_test_images)\n",
    "\n",
    "        # Mover as imagens para o diretório de teste\n",
    "        for image in test_images:\n",
    "            src_path = os.path.join(val_class_dir, image)\n",
    "            dst_path = os.path.join(test_class_dir, image)\n",
    "            shutil.move(src_path, dst_path)\n",
    "\n",
    "    print(\"Imagens de validação separadas para teste com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_dir = '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n",
    "print(\"Estrutura do diretório:\", os.listdir(dataset_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Exemplo de um modelo com camadas convolucionais\n",
    "model = Sequential([\n",
    "    # Camada de entrada com 3 canais (RGB)\n",
    "    Conv2D(32, (3, 3), input_shape=(256, 256, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # 3 classes\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumo do modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Gerador de treinamento\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/train',  # Caminho para o diretório de treino\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "# Gerador de validação\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/val',  # Caminho para a pasta de validação\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "# Gerador de teste\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '/content/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/test',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "# Treinamento do modelo\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10,  # Número de épocas\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def to_numpy(value):\n",
    "    # Se o valor for um tensor, converta para NumPy\n",
    "    if isinstance(value, np.ndarray):  # Verifica se é um array do NumPy\n",
    "        return value\n",
    "    elif isinstance(value, float):  # Se for float, retorne o valor diretamente\n",
    "        return value\n",
    "    else:  # Caso seja um tensor PyTorch, converta\n",
    "        return value.cpu().detach().numpy()\n",
    "\n",
    "def plot_metrics(metrics):\n",
    "    num_epochs = len(metrics['train_losses'])\n",
    "    epochs = np.arange(1, num_epochs + 1)\n",
    "\n",
    "    # Convertendo as métricas para arrays NumPy ou valores diretos\n",
    "    train_losses_np = metrics['train_losses']\n",
    "    val_losses_np = metrics['val_losses']\n",
    "    train_dices_np = [to_numpy(dice) for dice in metrics['train_dices']]\n",
    "    val_dices_np = [to_numpy(dice) for dice in metrics['val_dices']]\n",
    "\n",
    "    # Plot Losses\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses_np, label='Train Loss')\n",
    "    plt.plot(epochs, val_losses_np, label='Val Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Dice Coefficients\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_dices_np, label='Train Dice')\n",
    "    plt.plot(epochs, val_dices_np, label='Val Dice')\n",
    "    plt.title('Training and Validation Dice Coefficients')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Dice Coefficient')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Exemplo de estrutura de métricas para testar\n",
    "metrics = {\n",
    "    'train_losses': np.random.rand(10),  # Exemplo de perdas de treino\n",
    "    'val_losses': np.random.rand(10),  # Exemplo de perdas de validação\n",
    "    'train_dices': [np.random.rand() for _ in range(10)],  # Exemplo de Dice para treino\n",
    "    'val_dices': [np.random.rand() for _ in range(10)]  # Exemplo de Dice para validação\n",
    "}\n",
    "\n",
    "# Plotar as métricas\n",
    "plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar as previsões ignorando o último lote\n",
    "steps_per_epoch = test_generator.samples // test_generator.batch_size\n",
    "predictions = model.predict(test_generator, steps=steps_per_epoch, verbose=1)\n",
    "\n",
    "# Converter as previsões de probabilidade para rótulos de classe\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Obter os rótulos reais\n",
    "true_classes = test_generator.classes[:len(predicted_classes)]  # Garantir que os rótulos reais tenham o mesmo comprimento\n",
    "\n",
    "# Gerar a matriz de confusão\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Visualizar a matriz de confusão\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.xlabel('Previsões')\n",
    "plt.ylabel('Valores Reais')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
